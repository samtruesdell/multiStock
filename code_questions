ms_run.R: 
  line 49: do we really need to run for 150 years; would fewer years save a bit of computing time?
  lines 93-94: why do you need to sample from aval and bval? They are already random samples based on the empirial samples, 
               and resampling will "undo" the stratification into three groups, I think
  lines 100: Smsy_approx here is calculated by finding the escapement associated with the maximum total catch summed across all substocks
             for a shared exploitation rate (within the eq_ricker function), whereas Smsy_sum is the cumulative escapement associated 
             with the maximum catch for each stock exploited at it's own MSY rate (in effect assuming each stock can have a distinct U) 
             This is a potentially interesteing pair of quantities to compare - related to Brendans's paper.
  lines 103-117: not sure why this code is here, and what some of the variables represent (e.g., episd, pm.yr); ditto lines 129-131
                 update: now I see these are all defined in process.R
stock2mon.R:
  I'm not sure I understand what's going on here. Why does the selection of stocks to monitor depend on bias conditions? Perhaps this is to
  select either the most productive or the least productive stocks to monitor? Is this an important question/factor to consider?
process.R: 
  this is where the dynamic model is run; it is called twice - once for the data generating phase (with potentially a range of egoals
  over time, and a second time for the forecasting phase when egoal stays the same for each management scenario.
  I have looked over the code but it would be worth walking through it with Sam to explain several details. 
It doesn't look to me like it would be very difficult to set up a simulation with no differences in alpha and beta among substocks,
and with all stocks monitored and see if the results are the same as for the simple model, with the same conditions
